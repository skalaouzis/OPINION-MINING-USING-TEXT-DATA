import java.io.FileWriter

import org.apache.log4j.{Level, Logger}
import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification.NaiveBayes
import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
import org.apache.spark.ml.feature.{HashingTF, NGram, StopWordsRemover, Tokenizer}
import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}
import org.apache.spark.mllib.linalg.Vector
import org.apache.spark.sql.Row
import utils.Utils


 /*****************************************************************************
  *****************************************************************************
  ***** Authors: Giorgos Zafaras - Stavros Kalaouzis                      *****
  ***** Year: 2016-2017                                                   *****
  ***** Aristotle University of Thessaloniki: Computer Science Department *****
  *****************************************************************************
  *****************************************************************************/

object  test {

  def main(args: Array[String]) = {

    //set configuration for spark context
    val conf = new SparkConf()
      .setAppName("Opinion Mining")
      .setMaster("local[*]")
      .set("spark.executor.memory", "7g")


    //create spark context
    val sc = new SparkContext(conf)

    //get sql spark context
    val sqlContext = new org.apache.spark.sql.SQLContext(sc)

    //set logger
    val rootLogger = Logger.getRootLogger();
    rootLogger.setLevel(Level.ERROR);

    //necessary to transform RDD to Dataframe
    import sqlContext.implicits._


    //val positives = sc.textFile("/home/stavros/spark/positive-words.txt").map(opinion => (1D, StemmerController.stem(opinion)))  //kalaouzis
    val positives = sc.textFile("/home/stavros/merge_pos.csv").map(opinion => (1D, StemmerController.stem(opinion)))    //zafaras
    positives.cache()
    //set positives to {0, opinion}

    //val negatives = sc.textFile("/home/stavros/spark/negative-words.txt").map(opinion => (1D, StemmerController.stem(opinion))) //kalaouzis
    val negatives = sc.textFile("/home/stavros/merge-neg.csv").map(opinion => (0D, StemmerController.stem(opinion)))  //zafaras
    negatives.cache()

    //positives and negatives to one RDD with unique id
    val trainingRDD = positives.union(negatives).zipWithUniqueId().map(opinion => (opinion._2, opinion._1._2, opinion._1._1))
    trainingRDD.cache()
    //set dataframe column names
    val training = trainingRDD.toDF("id", "text", "label")
    training.cache()
    val testRDD = sc.textFile("/home/stavros/testdatafinal.csv").zipWithUniqueId().map(opinion => (opinion._2, StemmerController.stem(opinion._1)))
    //set dataframe column names
    val test = testRDD.toDF("id", "text")
    test.cache()


    val tokenizer = new Tokenizer()
      .setInputCol("text")
      .setOutputCol("words")
    val remover = new StopWordsRemover()
      .setInputCol("words")
      .setOutputCol("filtered")
      .setStopWords(Utils.getStopWords())
    val ngram = new NGram()
      .setInputCol("filtered")
      .setOutputCol("ngrams")
    val hashingTF = new HashingTF()
      .setInputCol(ngram.getOutputCol)
      .setOutputCol("features")
    /*

    val lr = new LogisticRegression()
      .setMaxIter(10)
    val pipeline = new Pipeline()
      .setStages(Array(tokenizer, remover, ngram, hashingTF, lr))

    val paramGrid = new ParamGridBuilder()
        .addGrid(ngram.n, Array(2))
        .addGrid(lr.regParam, Array(0.001))
        .build()
*/

    val nb = new NaiveBayes()


    // Chain indexers and forest in a Pipeline
    val pipeline = new Pipeline()
      .setStages(Array(tokenizer, remover, ngram, hashingTF, nb))

    val paramGrid = new ParamGridBuilder()
      .addGrid(nb.smoothing, Array(1.0))
      .addGrid(nb.modelType, Array("multinomial"))
      .addGrid(ngram.n, Array(2))
      .build()


    val cv = new CrossValidator()
      .setEstimator(pipeline)
      .setEvaluator(new BinaryClassificationEvaluator)
      .setEstimatorParamMaps(paramGrid)
      .setNumFolds(5)

    // Run cross-validation, and choose the best set of parameters.
    val cvModel = cv.fit(training)

    val fw = new FileWriter("nb_results.txt", true)

    cvModel.avgMetrics.foreach(metric => try {
      fw.write(metric + "\n")
    } catch {
      case e: Exception => println(e.printStackTrace())
    })

    // Make predictions on test documents. cvModel uses the best model found (lrModel).
    cvModel.transform(test)
      .select("id", "text", "probability", "prediction")
      .collect()
      .foreach {
        case Row(id: Long, opinion: String, prob: Vector, prediction: Double) =>
          println(s"($id) --> prob=$prob, prediction=$prediction")
          try {
            fw.write(s"($id) --> prob=$prob, prediction=$prediction\n")
          } catch {
            case e: Exception => println(e.printStackTrace())
          }
      }
    try {
      fw.close()
    } catch {
      case e: Exception => println(e.printStackTrace())
    }

  }

}

